{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating histogram, CDF and HDR plots from histrogram data in .csv format\n",
    "* also generates sequence plot from sequence data in .csv format\n",
    "\n",
    "### Input format\n",
    "* histogram data in csv format with two columns\n",
    "* latency (in nanosecond)\n",
    "* occurence\n",
    "* e.g. as generated by MoonGen\n",
    "* example:\n",
    "```\n",
    "1663,1\n",
    "1668,22\n",
    "1669,76\n",
    "1674,13\n",
    "1675,930\n",
    "1680,73\n",
    "1681,449\n",
    "```\n",
    "\n",
    "### Features\n",
    "* histogram, normalized histogram, CDF and HDR generation\n",
    "* optinal sequence plot generation\n",
    "* figures created in figures/*.tex\n",
    "* externalized data into data/*.tsv\n",
    "* TUMcolors supported\n",
    "* makefile to generate pdfs\n",
    "* same structure as expected by I8 thesis template\n",
    "* latency is converted to microsecond\n",
    "* histogram data is binned to microsecond resolution\n",
    "\n",
    "## You should not have to edit any of the following cells besides the last one\n",
    "* However you might want to tweak some plots manually\n",
    "\n",
    "## errors\n",
    "* if you get tex capacity exceeded when trying to compile the figures you have too many data points\n",
    " * solution: less bins, by rounding more (e.g. 10 or 100 microsecond resolution)\n",
    " * change: in to_microsecond change the dividend (from 1000 to 10000 or 100000)\n",
    " * result: not microsecond resolution/bins but 10 or 100 microsecond\n",
    " * dont forget to either update all axis labels or convert back to microsecond after binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "rprint=print\n",
    "from pprint import pprint as print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import other utility notebooks\n",
    "import import_ipynb\n",
    "# NOTE: tumcolors only work with python 3.6 and newer\n",
    "from util.tumcolor import tumcolor_cycler\n",
    "from util.i8_tikzplotlib import get_tikz_code, save_plt\n",
    "from util.loop_plot import _plot_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for command line invocation\n",
    "def run_from_cli():\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Generating plots from histogram data')\n",
    "    parser.add_argument('basepath', metavar='BASEPATH', type=str,\n",
    "                        help='Base path for all experiments')\n",
    "    parser.add_argument('--histogram-filename', metavar='HIST_FILENAME', type=str, default='histogram.csv',\n",
    "                        help='name of the histogram data file, wildcard possible')\n",
    "    parser.add_argument('--sequence-filename', metavar='SEQ_FILENAME', type=str, default='',\n",
    "                        help='name of the sequence data file, wildcard possible')\n",
    "    parser.add_argument('--name', type=str, default='',\n",
    "                        help='suffix for generated files, e.g. hdr-NAME.tex')\n",
    "    parser.add_argument('path', metavar='PATH', type=str, nargs='+',\n",
    "                        help='path to one or more csv file(s), will be RESULTS/<path>/HIST_FILENAME')\n",
    "    parser.add_argument('--label', metavar='LABEL', type=str, action='append',\n",
    "                        help='Nicer name for experiments')\n",
    "    parser.add_argument('--round-ms-digits', metavar='ROUND', type=int, default=3,\n",
    "                        help='Round to ROUND ms digits for binning')\n",
    "    parser.add_argument('--histogram-bar-width', metavar='BAR_WIDTH', type=float, default=0.005,\n",
    "                        help='Width for histogram bars')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    if args.label and not len(args.label) == len(args.path):\n",
    "        raise argparse.ArgumentTypeError('Must provide a label for either no or all paths')\n",
    "        \n",
    "    experiments = []\n",
    "    if args.label:\n",
    "        experiments = list(zip(args.path, args.label))\n",
    "    else:\n",
    "        experiments = args.path\n",
    "        \n",
    "    plot(experiments,\n",
    "         basepath=args.basepath,\n",
    "         histogram_file=args.histogram_filename,\n",
    "         sequence_file=args.sequence_filename,\n",
    "         name=args.name,\n",
    "         round_ms_digits=args.round_ms_digits,\n",
    "         histogram_bar_width=args.histogram_bar_width,\n",
    "    )\n",
    "        \n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_2c_csv(exp):\n",
    "    data = dict()\n",
    "    with open(exp) as infile:\n",
    "        for line in infile:\n",
    "            lat, occ = line.strip().split(',')\n",
    "            data[int(lat)] = int(occ)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_microsecond(data, keys=True, values=False):\n",
    "    if keys and values:\n",
    "        return {k / 1000: v / 1000 for k, v in data.items()}\n",
    "    if keys:\n",
    "        return {k / 1000: v for k, v in data.items()}\n",
    "    if values:\n",
    "        return {k: v / 1000 for k, v in data.items()}\n",
    "    \n",
    "def to_ms_bins(data, round_ms_digits=3):\n",
    "    binned = {}\n",
    "    for k, v in data.items():\n",
    "        rounded = round(k, round_ms_digits)\n",
    "        if rounded not in binned:\n",
    "            binned[rounded] = v\n",
    "        else:\n",
    "            binned[rounded] += v\n",
    "    return binned\n",
    "\n",
    "def to_expanded(data):\n",
    "    expanded = []\n",
    "    for val, occ in data.items():\n",
    "        expanded += [val] * occ\n",
    "    return expanded\n",
    "\n",
    "def normalize(data):\n",
    "    total = sum(data.values())\n",
    "    percs = {k: (v/total) for k, v in data.items()}\n",
    "    return percs\n",
    "\n",
    "def accumulate(data):\n",
    "    global curr\n",
    "    curr = 0\n",
    "    def acc(val): # just for the list comprehension\n",
    "        global curr\n",
    "        curr += val\n",
    "        return curr\n",
    "    return {k: acc(v) for k, v in sorted(data.items())}\n",
    "    \n",
    "def to_hdr(data):\n",
    "    # treat negative (>1.0) and exact 1.0 values and very high values for v\n",
    "    MAX_ACCURACY = 1000000000\n",
    "    return {k: 1/(1-v) for k, v in data.items() if not (1-v) == 0.0 and not 1/(1-v) < 0 and not 1/(1-v) > MAX_ACCURACY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hist_data(paths, basepath='/', histogram_file='histogram.csv', round_ms_digits=3,\n",
    "                      progression_mapping_function=None):\n",
    "    data = {}\n",
    "    if not isinstance(paths, list):\n",
    "        paths = [paths]\n",
    "\n",
    "    for path in paths:\n",
    "        name = None\n",
    "        if not isinstance(path, tuple):\n",
    "            name = path.replace('_', '-') # tex friendly path\n",
    "        else:\n",
    "            name = path[1]\n",
    "            path = path[0]\n",
    "            \n",
    "        extended_path = os.path.join(basepath, path)\n",
    "        experiment = os.path.join(extended_path, histogram_file)\n",
    "        rprint('Processing ' + extended_path)\n",
    "        \n",
    "        subexperiments = glob(experiment)\n",
    "        update_name = False\n",
    "        base_name = name\n",
    "        if len(subexperiments) > 1:\n",
    "            update_name = True\n",
    "        \n",
    "        for exp in subexperiments:\n",
    "            # replace everything that is not wildcard\n",
    "            if not (basepath == '.' or basepath == '..'):\n",
    "                histo = exp.replace(basepath, '')\n",
    "            histo = histo.replace(path, '')\n",
    "            histo = histo.replace(histogram_file, '')\n",
    "            histo = histo.replace('//', '/')\n",
    "            histo = histo[:-1]\n",
    "            \n",
    "            rprint('Subexperiment ' + histo)\n",
    "            if update_name:\n",
    "                name = base_name + histo\n",
    "                \n",
    "            # load data\n",
    "            try:\n",
    "                raw_data = read_2c_csv(exp)\n",
    "            except FileNotFoundError as exce:\n",
    "                rprint('Skipping - {}'.format(exce), file=sys.stderr)\n",
    "                continue\n",
    "                \n",
    "            # different processing steps\n",
    "            ms_data = to_microsecond(raw_data)\n",
    "            hist_data = to_ms_bins(ms_data, round_ms_digits=round_ms_digits)\n",
    "            box_data = to_expanded(ms_data)\n",
    "            normalized_data = normalize(hist_data)\n",
    "            accumulated_data = accumulate(normalized_data)\n",
    "            hdr_data = to_hdr(accumulated_data)\n",
    "            \n",
    "            \n",
    "            # store data\n",
    "            data[name] = {}\n",
    "            data[name]['hist'] = hist_data\n",
    "            data[name]['hist_norm'] = normalized_data\n",
    "            data[name]['cdf'] = accumulated_data\n",
    "            data[name]['hdr'] = hdr_data\n",
    "            data[name]['box'] = box_data\n",
    "            if progression_mapping_function:\n",
    "                data[name]['x_value'] = progression_mapping_function(exp)\n",
    "\n",
    "    return data\n",
    "\n",
    "def extract_sequence_data(paths, basepath='/', sequence_file='sequence.csv'):\n",
    "    data = {}\n",
    "    if not isinstance(paths, list):\n",
    "        paths = [paths]\n",
    "\n",
    "    for path in paths:\n",
    "        name = None\n",
    "        if not isinstance(path, tuple):\n",
    "            name = path.replace('_', '-') # tex friendly path\n",
    "        else:\n",
    "            name = path[1]\n",
    "            path = path[0]\n",
    "            \n",
    "        extended_path = os.path.join(basepath, path)\n",
    "        experiment = os.path.join(extended_path, sequence_file)\n",
    "        rprint('Processing ' + extended_path)\n",
    "        \n",
    "        subexperiments = glob(experiment)\n",
    "        update_name = False\n",
    "        base_name = name\n",
    "        if len(subexperiments) > 1:\n",
    "            update_name = True\n",
    "        \n",
    "        for exp in subexperiments:\n",
    "            # remove basepath and filename from what we will use as label\n",
    "            histo = exp.replace(basepath, '')\n",
    "            histo = histo.replace(sequence_file, '')\n",
    "            \n",
    "            rprint('Subexperiment ' + histo)\n",
    "            if update_name:\n",
    "                name = base_name + histo\n",
    "        \n",
    "            # load data\n",
    "            try:\n",
    "                raw_data = read_2c_csv(exp)\n",
    "            except FileNotFoundError as exce:\n",
    "                rprint('Skipping - {}'.format(exce), file=sys.stderr)\n",
    "                continue\n",
    "            \n",
    "            # different processing steps\n",
    "            seq_data = to_microsecond(raw_data, keys=False, values=True)\n",
    "            \n",
    "            \n",
    "            # store data\n",
    "            data[name] = {}\n",
    "            data[name]['seq'] = seq_data\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_values(xs, ys, sort_by='xs'):\n",
    "    # necessary for python <3.6\n",
    "    if sort_by == 'xs':\n",
    "        sort_by = 0\n",
    "    else:\n",
    "        sort_by = 1\n",
    "    tup = zip(xs, ys)\n",
    "    tup = sorted(tup, key=lambda x: x[sort_by])\n",
    "    xs = [x for x,_ in tup]\n",
    "    ys = [y for _,y in tup]\n",
    "    return xs, ys\n",
    "\n",
    "def plot_sequence(data, name=''):\n",
    "    fig, ax = plt.subplots(figsize=(12,6))\n",
    "    ax.set_prop_cycle(tumcolor_cycler)\n",
    "    \n",
    "    max_value = 0\n",
    "    min_value = 1000000\n",
    "    for exp, data in sorted(data.items()):\n",
    "        hist = data['seq']\n",
    "        xs = list(hist.keys())\n",
    "        ys = list(hist.values())\n",
    "        xs, ys = get_sorted_values(xs, ys)\n",
    "        max_value=max(max_value, max(xs))\n",
    "        min_value=min(min_value, min(xs))\n",
    "        ax.plot(xs, ys, marker='o', markersize=1, linestyle='', label=exp)\n",
    "\n",
    "    plt.ylim(bottom=0)\n",
    "                \n",
    "    ax.grid()\n",
    "    ax.set(ylabel='Latency [$\\mu$s]',\n",
    "           xlabel='Number [-]')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    \n",
    "    plt.xlim(left=min_value)\n",
    "    plt.xlim(right=max_value)\n",
    "    \n",
    "    save_plt('sequence', name=name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(data, name='', key='hist', ymax=None, ylabel='Occurence [-]',\n",
    "              historgram_bar_width=0.005):\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.set_prop_cycle(tumcolor_cycler)\n",
    "    \n",
    "    max_value = 0\n",
    "    data_points = 0\n",
    "    for exp, data in sorted(data.items()):\n",
    "        hist = data[key]\n",
    "        xs = list(hist.keys())\n",
    "        if key == 'hist':\n",
    "            factor = 1\n",
    "        else:\n",
    "            # assume normalized\n",
    "            factor = 100\n",
    "        ys = [factor * val for val in hist.values()]\n",
    "        if not ys:\n",
    "            continue\n",
    "        tup = zip(xs, ys)\n",
    "        tup = sorted(tup, key=lambda x: x[0])\n",
    "        xs, ys = get_sorted_values(xs, ys)\n",
    "        data_points += len(ys)\n",
    "        max_value=max(max_value, max(ys))\n",
    "        ax.bar(xs, ys, width=historgram_bar_width, label=exp)\n",
    "\n",
    "    print('Total amount of data points: {}'.format(data_points))\n",
    "    \n",
    "    if not ymax:\n",
    "        ymax = max_value\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.ylim(top=ymax)\n",
    "                \n",
    "    ax.grid()\n",
    "    ax.set(ylabel=ylabel,\n",
    "           xlabel='Latency [$\\mu$s]')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    \n",
    "    plt.xlim(left=0)\n",
    "    \n",
    "    save_plt(key, name=name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cdf(data, name=''):\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.set_prop_cycle(tumcolor_cycler)\n",
    "    \n",
    "    for exp, data in sorted(data.items()):\n",
    "        cdf = data['cdf']\n",
    "        xs = list(cdf.keys())\n",
    "        ys = [100 * val for val in cdf.values()]\n",
    "        xs, ys = get_sorted_values(xs, ys)\n",
    "        ax.plot(xs, ys, label=exp)\n",
    "\n",
    "\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.ylim(top=100)\n",
    "                \n",
    "    ax.grid()\n",
    "    ax.set(ylabel='CDF [\\%]',\n",
    "           xlabel='Latency [$\\mu$s]')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    \n",
    "    plt.xlim(left=0)\n",
    "    \n",
    "    save_plt('cdf', name=name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hdr(data, name=''):\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.set_prop_cycle(tumcolor_cycler)\n",
    "    \n",
    "    max_value = 0\n",
    "    min_value = 10000000000\n",
    "    for exp, data in sorted(data.items()):\n",
    "        hdr = data['hdr']\n",
    "        xs = list(hdr.values())\n",
    "        ys = list(hdr.keys())\n",
    "        if not ys:\n",
    "            continue\n",
    "        xs, ys = get_sorted_values(xs, ys)\n",
    "        max_value=max(max_value, max(ys))\n",
    "        min_value=min(min_value, min(ys))\n",
    "        ax.plot(xs, ys, label=exp)\n",
    "              \n",
    "            \n",
    "    # automatically determine min/max based on min/max values log10\n",
    "    log_max = pow(10, math.ceil(math.log10(max_value)))\n",
    "    log_min = pow(10, math.floor(math.log10(min_value)))\n",
    "    plt.ylim(bottom=log_min)\n",
    "    plt.ylim(top=log_max)\n",
    "                \n",
    "    ax.grid()\n",
    "    ax.set(xlabel='Percentile [\\%] (log)',\n",
    "           ylabel='Latency [$\\mu$s] (log)')\n",
    "    ax.set_xscale('log', subsx=[])\n",
    "    ax.set_yscale('log')\n",
    "    ticks = [1, 2, 10, 100, 1000, 10000, 100000, 1000000]\n",
    "    labels = [\"0\", \"50\", \"90\", \"99\", \"99.9\", \"99.99\", \"99.999\", \"99.9999\"]\n",
    "    plt.xticks(ticks, labels)\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.xlim(left=1)\n",
    "    # TODO determine xlim right\n",
    "\n",
    "    save_plt('hdr', name=name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(data, name=''):\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.set_prop_cycle(tumcolor_cycler)\n",
    "    \n",
    "    boxes = []\n",
    "    labels = []\n",
    "    for exp, data in sorted(data.items()):\n",
    "        values = data['box']\n",
    "        boxes.append(values)\n",
    "        labels.append(exp)\n",
    "    ax.boxplot(boxes, showfliers=True, whis=1.5, labels=labels, patch_artist=True,\n",
    "               medianprops=dict(color='TUMOrange'),\n",
    "               boxprops=dict(facecolor='TUMWhite', color='TUMBlack'),\n",
    "               \n",
    "            )\n",
    "            \n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xticks(ticks=range(1, len(labels) + 1), labels=labels)\n",
    "    plt.xlim(left=0.5, right=len(labels) + 0.5)\n",
    "                \n",
    "    ax.grid()\n",
    "    ax.set(xlabel='',\n",
    "           ylabel='Latency [$\\mu$s]')\n",
    "\n",
    "    save_plt('box', name=name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_progression(data, name='', percentiles=None, xlabel='Unknown [-]'):\n",
    "    if not percentiles:\n",
    "        percentiles = [50]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.set_prop_cycle(tumcolor_cycler)\n",
    "    \n",
    "    values = dict()\n",
    "    max_x_value = 0\n",
    "    min_x_value = 1000000\n",
    "    \n",
    "    # first gather data\n",
    "    for exp, data in sorted(data.items()):\n",
    "        test = '/'.join(exp.split('/')[:-1])\n",
    "        if test not in values:\n",
    "            values[test] = {}\n",
    "            \n",
    "        # get percentile from cdf data\n",
    "        for percentile in percentiles:\n",
    "            perc = -1\n",
    "            try:\n",
    "                perc = np.percentile(data['box'], percentile)\n",
    "            except IndexError:\n",
    "                pass\n",
    "            if not percentile in values[test]:\n",
    "                values[test][percentile] = []\n",
    "            values[test][percentile].append((data['x_value'], perc))\n",
    "        \n",
    "    # plot data per test and percentile\n",
    "    for exp, data in values.items():\n",
    "        for percentile, data in data.items():\n",
    "            data = sorted(data)\n",
    "            xs = [x for x, _ in data]\n",
    "            ys = [y for _, y in data]\n",
    "            max_x_value = max(max_x_value, max(xs))\n",
    "            min_x_value = min(max_x_value, min(xs))\n",
    "            ax.plot(xs, ys, label='{} ({}th percentile)'.format(exp, percentile), marker='x')\n",
    "\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xlim(left=min_x_value)\n",
    "    plt.xlim(right=max_x_value)\n",
    "                \n",
    "    ax.grid()\n",
    "    ax.set(ylabel='Latency [$\\mu$s]',\n",
    "           xlabel=xlabel)\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 1))\n",
    "    \n",
    "    save_plt('progression_{}'.format('_'.join([str(p) for p in percentiles])), name=name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loop(name, content, mapping, hist_data, key=None):\n",
    "    if not key:\n",
    "        key = [50]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.set_prop_cycle(tumcolor_cycler)\n",
    "    \n",
    "    axis_label = None\n",
    "    xss = {}\n",
    "    yss = {}\n",
    "    mapped = {}\n",
    "    \n",
    "    # gather data based on mapping\n",
    "    for exp, run, type in content:\n",
    "        axis_label = list(type.keys())[0]\n",
    "        if exp not in xss:\n",
    "            xss[exp] = []\n",
    "            yss[exp] = {}\n",
    "        xss[exp].append(list(type.values())[0])\n",
    "        try:\n",
    "            mapped[exp] = hist_data[mapping[exp][run]]\n",
    "        except KeyError as exce:\n",
    "            continue\n",
    "        else:\n",
    "            data = mapped[exp]\n",
    "            for percentile in key:\n",
    "                perc = -1\n",
    "                try:\n",
    "                    perc = np.percentile(data['box'], percentile)\n",
    "                except IndexError:\n",
    "                    pass\n",
    "                if not percentile in yss[exp]:\n",
    "                    yss[exp][percentile] = []\n",
    "                yss[exp][percentile].append(perc)\n",
    "        \n",
    "    for exp, data in sorted(mapped.items()):\n",
    "        for percentile in sorted(key):\n",
    "            ys = yss[exp][percentile]\n",
    "            xs = xss[exp]\n",
    "            zipped = list(zip(xs, ys))\n",
    "            zipped.sort(key=lambda tup: tup[0])\n",
    "            xs, ys = zip(*zipped)\n",
    "            \n",
    "            ax.plot(xs, ys, marker='x', label = exp)\n",
    "    \n",
    "    plt.ylim(bottom=0)\n",
    "    #plt.xlim(left=min_x_value)\n",
    "    #plt.xlim(right=max_x_value)\n",
    "                \n",
    "    ax.grid()\n",
    "    ax.set(ylabel='Latency [$\\mu$s]',\n",
    "           xlabel=axis_label)\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    save_plt('loop_{}'.format('_'.join([str(p) for p in key])), name=name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_sequence(paths, name, sequence_file, **kwargs):\n",
    "    print('------------- plotting sequence data ------------')\n",
    "    seq_data = extract_sequence_data(paths, sequence_file=sequence_file, **kwargs)\n",
    "    if not seq_data:\n",
    "        rprint('No sequence data found', file=sys.stderr)\n",
    "    else:\n",
    "        plot_sequence(seq_data, name)\n",
    "        \n",
    "def _plot_default_histogram(name, hist_data, historgram_bar_width):\n",
    "    print('------------ plotting default histogram data ----------')\n",
    "    # different plot types for histogram data\n",
    "    plot_hist(hist_data, name, historgram_bar_width=historgram_bar_width)\n",
    "    plot_hist(hist_data, name, key='hist_norm', ylabel='Occurence [\\%]',\n",
    "              historgram_bar_width=historgram_bar_width)\n",
    "    plot_box(hist_data, name)\n",
    "    plot_cdf(hist_data, name)\n",
    "    plot_hdr(hist_data, name)\n",
    "    \n",
    "def _plot_progression(hist_data, name, progression_x_label, progression_percentiles):\n",
    "    print('------------ progression plots ----------------')\n",
    "    for percentiles in progression_percentiles:\n",
    "        plot_progression(hist_data, name, percentiles=percentiles, xlabel=progression_x_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(paths, name=None, default_plots=True, percentiles=None,\n",
    "         histogram_file=None, round_ms_digits=3, historgram_bar_width=0.005,\n",
    "         sequence_file=None,\n",
    "         progression_mapping_function=None, progression_x_label=None,\n",
    "         loop_file=None, loop_order=None,\n",
    "         **kwargs):\n",
    "    \n",
    "    if sequence_file:\n",
    "        _plot_sequence(paths, name, sequence_file, **kwargs)\n",
    "    \n",
    "    if histogram_file:\n",
    "        # histogram data\n",
    "        hist_data = extract_hist_data(paths, histogram_file=histogram_file, round_ms_digits=round_ms_digits,\n",
    "                                      progression_mapping_function=progression_mapping_function,\n",
    "                                      **kwargs)\n",
    "        if not hist_data:\n",
    "            rprint('No histogram data found', file=sys.stderr)\n",
    "            return\n",
    "        \n",
    "        if default_plots:\n",
    "            _plot_default_histogram(name, hist_data, historgram_bar_width)\n",
    "            \n",
    "    if not percentiles:\n",
    "        print('you need to define the percentiles of interest as list of lists')\n",
    "        return\n",
    "\n",
    "    if (progression_mapping_function and not progression_x_label) or (progression_x_label and not progression_mapping_function):\n",
    "        raise RuntimeError('must define progression_mapping_function AND progression_x_label if using loop variables')\n",
    "    if progression_mapping_function and progression_x_label:\n",
    "        _plot_progression(hist_data, name, progression_x_label, percentiles)\n",
    "        \n",
    "    if (loop_file and not loop_order) or (loop_order and not loop_file):\n",
    "        raise RuntimeError('must define loop_file AND loop_order if using loop variables')\n",
    "    if loop_file and loop_order:\n",
    "        _plot_loop(paths, name, hist_data, loop_file, loop_order, percentiles, plot_loop, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will only be triggered if invoked from command-line\n",
    "if not sys.argv[0].endswith('ipykernel_launcher.py'):\n",
    "    run_from_cli()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make your edits in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base path for all your experiments\n",
    "# e.g. if all your experiments are in /srv/testbed/results/USER/default/\n",
    "# with subexperiments that have the HISTOGRAM_FILENAME in\n",
    "# 2020-02-23_13-44-39_703517/litecoincash/9000-0064\n",
    "# 2020-02-23_13-44-39_703517/litecoincash/9000-0065\n",
    "# 2019-02-23_13-44-39_703517/litecoincash/9000-0064\n",
    "RESULTS='sample_data'\n",
    "# HISTOGRAM_FILENAME may contain wildcard\n",
    "HISTOGRAM_FILENAME = 'histogram_run*.csv'\n",
    "\n",
    "# fine tuning parameters for histograms\n",
    "ROUND_MS_DIGITS = 1\n",
    "HISTOGRAM_BAR_WIDTH = 0.5\n",
    "\n",
    "# plot expects a list of subexperiments that will be combined like the following\n",
    "#    RESULTS/<subexperiment>/HISTOGRAM_FILENAME\n",
    "# each subexperiment is either defined as\n",
    "# - string, used as path to experiment and as legend entry\n",
    "# - tuple of (path, name) where name will be used as legend entry for this subexperiment\n",
    "# works the same for optional SEQUENCE_FILENAME\n",
    "# optional keyword 'name': added to output files\n",
    "\n",
    "# you now have three options for plotting\n",
    "# #1: plot the latency output of each experiment run\n",
    "# usually this is NOT what you want but can be helpful to check that your experiment actually ran\n",
    "# this will generate a lot of plots and will take some time (and might be unreadable)\n",
    "plot([\n",
    "      ('2020-09-04_17-08-15_063541/bitcoin', 'Test1'),\n",
    "     ],\n",
    "     basepath=RESULTS,\n",
    "     name='sample',\n",
    "    \n",
    "     histogram_file=HISTOGRAM_FILENAME,\n",
    "     round_ms_digits=ROUND_MS_DIGITS,\n",
    "     historgram_bar_width=HISTOGRAM_BAR_WIDTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS='sample_data'\n",
    "HISTOGRAM_FILENAME = 'histogram_run*.csv'\n",
    "\n",
    "# #2: plot a progression of your experiment\n",
    "# usually you have one parameter in your experiment runs changing\n",
    "# if you have encoded this into the filename, you can plot it\n",
    "\n",
    "# you need to define this function\n",
    "def progression_mapping_function(exp):\n",
    "    # in case you want to plot the progression of\n",
    "    # experiments within one experiment folder\n",
    "    # this function maps a certain run (one output file within this\n",
    "    # experiment) to the x value used for the progression\n",
    "    \n",
    "    # in this example case the progression is based on the run number\n",
    "    # which is encoded in the path (the wildcard in the histogram file)\n",
    "    val = float(exp.split('_run')[-1].split('.')[0])\n",
    "    return val\n",
    "\n",
    "# as before, but with progression_* parameters\n",
    "# percentiles defines which percentiles you want per plot\n",
    "plot([\n",
    "      ('2020-09-04_17-08-15_063541/bitcoin', 'Test1'),\n",
    "     ],\n",
    "     basepath=RESULTS,\n",
    "     name='sample',\n",
    "     histogram_file=HISTOGRAM_FILENAME,\n",
    "    \n",
    "     percentiles=[[50], [0, 100]],\n",
    "     default_plots=False, # do not plot #1 plots\n",
    "    \n",
    "     progression_mapping_function=progression_mapping_function,\n",
    "     progression_x_label='Packet Size [B]',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS='sample_data'\n",
    "HISTOGRAM_FILENAME = 'histogram_run*.csv'\n",
    "\n",
    "# can include wildcards\n",
    "LOOP_FILENAME = '*_unknown_run*.loop'\n",
    "\n",
    "# #3: using a pos loop experiment\n",
    "# define the format of the loopfile\n",
    "# and define the order of the loop parameters\n",
    "plot([\n",
    "      ('2020-09-04_17-08-15_063541/bitcoin', 'Test1'),\n",
    "     ],\n",
    "     basepath=RESULTS,\n",
    "     name='sample',\n",
    "     histogram_file=HISTOGRAM_FILENAME,\n",
    "    \n",
    "     percentiles=[[50], [0, 100]],\n",
    "     default_plots=False,\n",
    "    \n",
    "     loop_file=LOOP_FILENAME,\n",
    "     loop_order=['pkt_sz', 'cpu_frequency', 'pkt_rate'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS='/srv/testbed/results/stubbe/modanet/'\n",
    "SEQUENCE_FILENAME = 'sequence.csv'\n",
    "\n",
    "# you can plot only the sequence data\n",
    "plot([\n",
    "      ('2020-02-23_13-44-39_703517/litecoincash/*', 'Baseline'),\n",
    "     ],\n",
    "     basepath=RESULTS,\n",
    "     sequence_file=SEQUENCE_FILENAME,\n",
    "     name='sample',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
